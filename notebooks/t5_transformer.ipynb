{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Description\n",
        "Use the T5 models to perform several NLP tasks."
      ],
      "metadata": {
        "id": "1Dss-9tf3_5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Up"
      ],
      "metadata": {
        "id": "4QgpZleX4Y9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-large')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-large', return_dict=True)"
      ],
      "metadata": {
        "id": "HYzOCJIg4m3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarization"
      ],
      "metadata": {
        "id": "OuhkP4Qt54mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = (\"Deep learning is a subset of machine learning, which is essentially a neural network with three or more layers. These neural networks attempt to simulate the behavior of the human brain—albeit far from matching its ability—allowing it to “learn” from large amounts of data. While a neural network with a single layer can still make approximate predictions, additional hidden layers can help to optimize and refine for accuracy. \"\n",
        "      \"Deep learning drives many artificial intelligence (AI) applications and services that improve automation, performing analytical and physical tasks without human intervention. Deep learning technology lies behind everyday products and services (such as digital assistants, voice-enabled TV remotes, and credit card fraud detection) as well as emerging technologies (such as self-driving cars).\")\n",
        "\n",
        "inputs = tokenizer.encode(\"summarize: \" + sequence,\n",
        "                          return_tensors='pt',\n",
        "                          max_length=512,\n",
        "                          truncation=True)\n",
        "\n",
        "output = model.generate(inputs, max_length=80, min_length=40)\n",
        "summary = tokenizer.decode(output[0])\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "zoKEn0rq51pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Translation"
      ],
      "metadata": {
        "id": "ySqOcju88ik8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = (\"Apples may lower your risk for cancer, diabetes, and heart disease. Research says apples may also help with weight loss, while improving your gut and brain health.\")\n",
        "\n",
        "inputs = tokenizer(\"translate English to French: \"+ sequence, return_tensors=\"pt\").input_ids\n",
        "\n",
        "output = model.generate(inputs)\n",
        "translation = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(translation)"
      ],
      "metadata": {
        "id": "tIn-jSFy8pDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification"
      ],
      "metadata": {
        "id": "0vRrDPeS-hir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "premise = (\"I hate reading\")\n",
        "hypothesis = (\"I spend six hours every day reading books\")\n",
        "\n",
        "inputs = tokenizer(\"mnli premise: \"+ premise +\" hypothesis: \"+ hypothesis, return_tensors=\"pt\").input_ids\n",
        "\n",
        "output = model.generate(inputs)\n",
        "decoder = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(decoder)\n"
      ],
      "metadata": {
        "id": "IsUNaZoY-luh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linguistic Acceptability"
      ],
      "metadata": {
        "id": "qAn9aNh1_RqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = (\"You I they\")\n",
        "\n",
        "for sequence in [\"You I they\",\n",
        "                 \"Be happy\",\n",
        "                 \"Everything will be okay\"]:\n",
        "\n",
        "  inputs = tokenizer(\"cola sentence: \"+ sequence, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  output = model.generate(inputs)\n",
        "  decoder = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  print(decoder)"
      ],
      "metadata": {
        "id": "XGqrX67L_Uvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Similarity"
      ],
      "metadata": {
        "id": "P5ohARZYBX61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sequence1, sequence2 in [[\"I like traveling\", \"It's sunny today\"],\n",
        "                            [\"I'm happy\", \"I'm jubilant\"]]:\n",
        "\n",
        "  inputs = tokenizer(\"stsb sentence 1: \"+ sequence1 +\" sentence 2: \"+ sequence2,\n",
        "                    return_tensors=\"pt\").input_ids\n",
        "\n",
        "  output = model.generate(inputs)\n",
        "  decoder = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  print(decoder)"
      ],
      "metadata": {
        "id": "xSwFqL91Bbc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}